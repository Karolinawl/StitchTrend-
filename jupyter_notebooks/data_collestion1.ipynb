{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1394d9b8",
   "metadata": {},
   "source": [
    "This notebook focuses on collecting and preparing data from the Raverly API.\n",
    "he main goals are to:\n",
    "- fetch publicly available knitting pattern data using the Ravelry API,\n",
    "- build an initial raw dataset containing pattern metadata,\n",
    "- clean and structure the data for further analysis,\n",
    "- prepare the dataset for exploratory data analysis (EDA) and later modelling.\n",
    "\n",
    "This is the first step of the project. I will concentrate on data collection and basic data preparation for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9119ccf",
   "metadata": {},
   "source": [
    "1. Import libraries for data handling, API calls, and quick visual checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16adac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC DATA HANDLING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# API & REQUESTS\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# VISUALISATION (later use)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Settings for nicer plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a731696",
   "metadata": {},
   "source": [
    "2. Define and create folders for raw and processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e03c2f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/raw/v1', '../data/processed/v1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAW_DIR = \"../data/raw/v1\"\n",
    "PROCESSED_DIR = \"../data/processed/v1\"\n",
    "\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "RAW_JSON_PATH = os.path.join(RAW_DIR, \"patterns_raw.json\")\n",
    "RAW_CSV_PATH = os.path.join(RAW_DIR, \"patterns_raw.csv\")\n",
    "\n",
    "PROCESSED_CSV_PATH = os.path.join(PROCESSED_DIR, \"patterns_clean.csv\")\n",
    "\n",
    "RAW_DIR, PROCESSED_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ea694",
   "metadata": {},
   "source": [
    "3. API Credentials. They are loaded from enviroment variables. They are stored locally as environment variables to prevent accidental exposure in the codebase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "115319a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials loaded ✅\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # loads variables from .env\n",
    "\n",
    "RAVELRY_USER = os.getenv(\"RAVELRY_ACCESS_KEY\")\n",
    "RAVELRY_PASS = os.getenv(\"RAVELRY_PERSONAL_KEY\")\n",
    "\n",
    "if not RAVELRY_USER or not RAVELRY_PASS:\n",
    "    raise ValueError(\n",
    "        \"API credentials not found. \"\n",
    "        \"Make sure RAVELRY_ACCESS_KEY and RAVELRY_PERSONAL_KEY are set in .env file.\"\n",
    "    )\n",
    "\n",
    "print(\"Credentials loaded ✅\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6895c4f0",
   "metadata": {},
   "source": [
    "4. Test public API endpoint (read-only) and inspect response structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3c2bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Content-Type: application/json; charset=utf-8\n",
      "Preview: {\"patterns\": [{\"free\":false,\"id\":7497838,\"name\":\"BABA sweater Chunky\",\"permalink\":\"baba-sweater-chunky\",\"personal_attributes\":null,\"first_photo\":{\"id\":145451206,\"sort_order\":1,\"user_id\":811200,\"x_offs\n",
      "Top-level keys: ['patterns', 'paginator']\n",
      "Patterns returned: 5\n"
     ]
    }
   ],
   "source": [
    "search_url = f\"{BASE_URL}/patterns/search.json\" # Endpoint for pattern search\n",
    "params = {\"query\": \"sweater\", \"page\": 1, \"page_size\": 5}\n",
    "\n",
    "resp = requests.get(search_url, params=params, auth=auth, timeout=30) # Make the GET request\n",
    "\n",
    "print(\"Status:\", resp.status_code)\n",
    "print(\"Content-Type:\", resp.headers.get(\"Content-Type\"))\n",
    "print(\"Preview:\", resp.text[:200])\n",
    "\n",
    "if resp.ok:\n",
    "    data = resp.json()\n",
    "    print(\"Top-level keys:\", list(data.keys()))\n",
    "    print(\"Patterns returned:\", len(data.get(\"patterns\", [])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb5a8b",
   "metadata": {},
   "source": [
    "5. Fetch patterns from Raverly API (RAW), and save raw response to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c84de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "Fetching page 2...\n",
      "Fetching page 3...\n",
      "Total patterns collected: 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/v1\\\\patterns_raw.json'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_url = f\"{BASE_URL}/patterns/search.json\" # Endpoint for pattern search\n",
    "\n",
    "query = \"sweater\"   # Search term\n",
    "page = 1\n",
    "page_size = 100   \n",
    "max_pages = 3     \n",
    "\n",
    "all_patterns = []\n",
    "\n",
    "while page <= max_pages:\n",
    "    print(f\"Fetching page {page}...\")\n",
    "    \n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"page\": page,\n",
    "        \"page_size\": page_size\n",
    "    }\n",
    "    \n",
    "    resp = requests.get(search_url, params=params, auth=auth, timeout=30)\n",
    "    \n",
    "    if not resp.ok:\n",
    "        print(f\"Stopped at page {page}, status {resp.status_code}\")\n",
    "        break\n",
    "    \n",
    "    data = resp.json()\n",
    "    patterns = data.get(\"patterns\", [])\n",
    "    \n",
    "    all_patterns.extend(patterns)\n",
    "    \n",
    "    if len(patterns) < page_size:\n",
    "        # no more pages\n",
    "        break\n",
    "    \n",
    "    page += 1\n",
    "    time.sleep(1)  \n",
    "\n",
    "print(f\"Total patterns collected: {len(all_patterns)}\")\n",
    "\n",
    "# Save RAW data to JSON\n",
    "with open(RAW_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_patterns, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "RAW_JSON_PATH\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
